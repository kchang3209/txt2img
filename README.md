# CSE247 Project: Coding via Text-as-Image (Multimodal LLM)

Processing long text inputs in LLMs can be expensive. Recent work explores representing text as images (“text-as-image”) to improve computational efficiency and accuracy via vision-language models.

This project evaluates text-as-image for coding (fixing bugs) using a multimodal LLM (VLM) and evaluates accuracy vs text-only approaches, token compression/speed-up, and the tooling needed to generate code snapshot images for model input.